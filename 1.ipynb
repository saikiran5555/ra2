{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0a2e06",
   "metadata": {},
   "source": [
    "R-squared, also known as the coefficient of determination, is a statistical measure in linear regression models that represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It provides an indication of the goodness of fit of a regression model.\n",
    "\n",
    "Concept of R-squared\n",
    "Interpretation: R-squared values range from 0 to 1. A higher R-squared value indicates that a larger proportion of variance in the dependent variable is explained by the independent variables in the model. An R-squared of 1 suggests that the regression predictions perfectly fit the data.\n",
    "\n",
    "Limitations: While a higher R-squared is generally preferable, it is not a definitive measure of a model's quality. It does not indicate whether the regression model is appropriate or whether every explanatory variable is relevant. Moreover, R-squared can be artificially increased by adding more predictors, regardless of their relevance.\n",
    "\n",
    "Calculation of R-squared\n",
    "R-squared is calculated based on the proportion of total variation in the dependent variable that is explained by the independent variable(s) in the model. The formula is:\n",
    "\n",
    "�\n",
    "2\n",
    "=\n",
    "1\n",
    "−\n",
    "�\n",
    "�\n",
    "res\n",
    "�\n",
    "�\n",
    "tot\n",
    "R \n",
    "2\n",
    " =1− \n",
    "SS \n",
    "tot\n",
    "​\n",
    " \n",
    "SS \n",
    "res\n",
    "​\n",
    " \n",
    "​\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "�\n",
    "�\n",
    "res\n",
    "SS \n",
    "res\n",
    "​\n",
    "  is the sum of squares of residuals (also known as the residual sum of squares). It measures the variation in the dependent variable that is not explained by the model.\n",
    "�\n",
    "�\n",
    "tot\n",
    "SS \n",
    "tot\n",
    "​\n",
    "  is the total sum of squares (also known as the total variation in the dependent variable). It is the sum of squares of the difference between the dependent variable and its mean.\n",
    "Understanding R-squared\n",
    "0% (0.0): Indicates that the model explains none of the variability of the response data around its mean. The independent variables do not explain the variation in the dependent variable.\n",
    "\n",
    "100% (1.0): Indicates that the model explains all the variability of the response data around its mean. This usually means a perfect fit, which is rare in practice and might suggest overfitting.\n",
    "\n",
    "Example\n",
    "Suppose you have an R-squared value of 0.75 in a linear regression model predicting house prices based on square footage. This means that 75% of the variation in house prices is explained by the square footage. The remaining 25% of the variation is due to other factors not included in the model or inherent variability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
